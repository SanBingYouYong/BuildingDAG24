{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9IoFDl_pmQ8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import yaml\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load dataset and normalization ranges\n",
        "dataset_path = \"./datasets/test_dataset\"\n",
        "image_folder = os.path.join(dataset_path, \"images\")\n",
        "params_folder = os.path.join(dataset_path, \"params\")\n",
        "ranges_file = os.path.join(dataset_path, \"ranges.yml\")\n",
        "\n",
        "with open(ranges_file, \"r\") as file:\n",
        "    normalization_ranges = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "# Function to load and preprocess the dataset\n",
        "def load_dataset(image_folder, params_folder, normalization_ranges):\n",
        "    images = []\n",
        "    params = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(\".png\"):\n",
        "            # Load and preprocess images\n",
        "            img_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (512, 512))  # Resize to your desired input size\n",
        "            img = img / 255.0  # Normalize to [0, 1]\n",
        "            images.append(img)\n",
        "\n",
        "            # Load corresponding parameters\n",
        "            param_file_path = os.path.join(params_folder, f\"{os.path.splitext(filename)[0]}.yml\")\n",
        "            with open(param_file_path, \"r\") as param_file:\n",
        "                param_data = yaml.load(param_file, Loader=yaml.FullLoader)\n",
        "                params.append(param_data)\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    images = np.array(images)\n",
        "    params = np.array(params)\n",
        "\n",
        "    # Normalize parameters using MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    params_normalized = scaler.fit_transform(params)\n",
        "\n",
        "    return images, params_normalized\n",
        "\n",
        "# Load the dataset\n",
        "images, params_normalized = load_dataset(image_folder, params_folder, normalization_ranges)\n",
        "\n",
        "# Define the VGG model as encoder\n",
        "# You can load the pre-trained VGG model from Keras applications\n",
        "from tensorflow.keras.applications import VGG16\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "encoder_output = vgg_model.output\n",
        "\n",
        "# Add your own decoder layers\n",
        "decoder_input = layers.Flatten()(encoder_output)\n",
        "decoder_output = layers.Dense(units=your_output_units, activation='your_activation_function')(decoder_input)\n",
        "\n",
        "# Create your model\n",
        "model = models.Model(inputs=vgg_model.input, outputs=decoder_output)\n",
        "\n",
        "# Compile your model with the appropriate loss and optimizer\n",
        "model.compile(optimizer='your_optimizer', loss='your_loss_function')\n",
        "\n",
        "# Train your model using images and normalized parameters\n",
        "model.fit(images, params_normalized, epochs=your_epochs, batch_size=your_batch_size, validation_split=your_validation_split)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "GB1ZFzoD--gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Encoder using VGG (you may replace it with your desired encoder)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        # Example VGG-like architecture for demonstration\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # size: 512x512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 256x256\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # size: 256x256\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 128x128\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # size: 128x128\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 64x64\n",
        "            nn.Flatten(),  # size: 64x64\n",
        "            nn.Linear(64 * 64 * 64, 4096)  # size: 4096\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x\n",
        "\n",
        "model = 1"
      ],
      "metadata": {
        "id": "OraO9_Bk-6GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder-Decoders (own)\n",
        "\n",
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define Encoder using VGG (you may replace it with your desired encoder)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # size: 512x512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 256x256\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # size: 256x256\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 128x128\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # size: 128x128\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 64x64\n",
        "            nn.Flatten(),  # size: 64x64\n",
        "            nn.Linear(64 * 64 * 64, 4096)  # size: 4096\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x\n",
        "\n",
        "# Define Decoder using a simple 3-layer MLP\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the ranges from the YAML file\n",
        "with open('./ranges.yml', 'r') as file:\n",
        "    ranges = yaml.safe_load(file)\n",
        "\n",
        "# Create a mapping between parameter names and output sizes\n",
        "parameter_output_mapping = {}\n",
        "for param_name, param_specs in ranges.items():\n",
        "    if param_specs['type'] == 'float':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'int':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'vector':\n",
        "        parameter_output_mapping[param_name] = 3  # 3 for x, y, z\n",
        "    elif param_specs['type'] == 'states':\n",
        "        parameter_output_mapping[param_name] = len(param_specs['values'])\n",
        "    elif param_specs['type'] == 'bool':\n",
        "        parameter_output_mapping[param_name] = 2  # 2 for binary encoding\n",
        "\n",
        "# Create decoders based on the mapping\n",
        "decoders = nn.ModuleDict({\n",
        "    param_name: Decoder(4096, output_size)\n",
        "    for param_name, output_size in parameter_output_mapping.items()\n",
        "})\n",
        "\n",
        "# Complete model with one Pre-trained Encoder and multiple Decoders\n",
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self, encoder, decoders):\n",
        "        super(EncoderDecoderModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoders = decoders\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        print(x.size())\n",
        "        batch_size = x.size(0)  # Get the batch size\n",
        "        x = x.view(batch_size, -1)  # Flatten the feature tensor, considering the batch size\n",
        "        decoder_outputs = {param_name: decoder(x) for param_name, decoder in self.decoders.items()}\n",
        "        return decoder_outputs\n",
        "\n",
        "# Example usage\n",
        "# Create an instance of the EncoderDecoderModel with a pre-trained encoder\n",
        "encoder = Encoder()  # Use your pre-trained encoder here\n",
        "model = EncoderDecoderModel(encoder, decoders)\n",
        "\n",
        "# Example input tensor with shape (batch_size, channels, height, width)\n",
        "input_tensor = torch.randn(2, 1, 512, 512)\n",
        "\n",
        "# Forward pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Print the output shapes for each decoder\n",
        "for param_name, decoder_output in output.items():\n",
        "    print(f\"{param_name} decoder output shape: {decoder_output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCZ6WJBC9ops",
        "outputId": "a0996e20-9ed0-4527-bf3c-83b98bb2b35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4096])\n",
            "Bm Base Shape decoder output shape: torch.Size([2, 2])\n",
            "Bm Size decoder output shape: torch.Size([2, 3])\n",
            "Floor Ledge Extrusion X decoder output shape: torch.Size([2, 1])\n",
            "Floor Ledge Extrusion Z decoder output shape: torch.Size([2, 1])\n",
            "Floor Ledge Size X decoder output shape: torch.Size([2, 1])\n",
            "Floor Ledge Size Z decoder output shape: torch.Size([2, 1])\n",
            "Has Floor Ledge decoder output shape: torch.Size([2, 2])\n",
            "Has Window Ledge decoder output shape: torch.Size([2, 2])\n",
            "Num Floors decoder output shape: torch.Size([2, 1])\n",
            "Num Windows Each Side decoder output shape: torch.Size([2, 1])\n",
            "Rf Base Shape decoder output shape: torch.Size([2, 3])\n",
            "Rf Size decoder output shape: torch.Size([2, 3])\n",
            "Window Divided Horizontal decoder output shape: torch.Size([2, 2])\n",
            "Window Divided Vertical decoder output shape: torch.Size([2, 2])\n",
            "Window Interpanel Offset Percentage Y decoder output shape: torch.Size([2, 1])\n",
            "Window Interpanel Offset Percentage Z decoder output shape: torch.Size([2, 1])\n",
            "Window Ledge Extrusion X decoder output shape: torch.Size([2, 1])\n",
            "Window Ledge Extrusion Z decoder output shape: torch.Size([2, 1])\n",
            "Window Ledge Shape Size decoder output shape: torch.Size([2, 3])\n",
            "Window Ledges Height Offset decoder output shape: torch.Size([2, 1])\n",
            "Window Panel Area decoder output shape: torch.Size([2, 3])\n",
            "Window Shape Size decoder output shape: torch.Size([2, 3])\n",
            "Windows Height Offset decoder output shape: torch.Size([2, 1])\n",
            "Windows Left Right Offset decoder output shape: torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "8Bjj-uLEEgmV",
        "outputId": "7a18312a-87e1-4433-9ab4-0a0f0617ead0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-84f271e8-a7a0-4f8d-9e4b-b3b2794f8090\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-84f271e8-a7a0-4f8d-9e4b-b3b2794f8090\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_dataset0202.zip to test_dataset0202.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test_dataset0202.zip"
      ],
      "metadata": {
        "id": "eVbpLXTJqMwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir datasets"
      ],
      "metadata": {
        "id": "iTsGR1-3qgJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv test_dataset/ datasets/"
      ],
      "metadata": {
        "id": "nBdnVFxRqSil"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder-Decoders\n",
        "\n",
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define Encoder using VGG (you may replace it with your desired encoder)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # size: 512x512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 256x256\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # size: 256x256\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 128x128\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # size: 128x128\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 64x64\n",
        "            nn.Flatten(),  # size: 64x64\n",
        "            nn.Linear(64 * 64 * 64, 4096)  # size: 4096\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x\n",
        "\n",
        "# Define Decoder using a simple 3-layer MLP\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the ranges from the YAML file\n",
        "with open('./ranges.yml', 'r') as file:\n",
        "    ranges = yaml.safe_load(file)\n",
        "\n",
        "# Create a mapping between parameter names and output sizes\n",
        "parameter_output_mapping = {}\n",
        "for param_name, param_specs in ranges.items():\n",
        "    if param_specs['type'] == 'float':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'int':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'vector':\n",
        "        parameter_output_mapping[param_name] = 3  # 3 for x, y, z\n",
        "    elif param_specs['type'] == 'states':\n",
        "        parameter_output_mapping[param_name] = len(param_specs['values'])\n",
        "    elif param_specs['type'] == 'bool':\n",
        "        parameter_output_mapping[param_name] = 2  # 2 for binary encoding\n",
        "\n",
        "# Create decoders based on the mapping\n",
        "decoders = nn.ModuleDict({\n",
        "    param_name: Decoder(4096, output_size)\n",
        "    for param_name, output_size in parameter_output_mapping.items()\n",
        "})\n",
        "\n",
        "# Complete model with one Pre-trained Encoder and multiple Decoders\n",
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self, encoder, decoders):\n",
        "        super(EncoderDecoderModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoders = decoders\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        print(x.size())\n",
        "        batch_size = x.size(0)  # Get the batch size\n",
        "        x = x.view(batch_size, -1)  # Flatten the feature tensor, considering the batch size\n",
        "        decoder_outputs = {param_name: decoder(x) for param_name, decoder in self.decoders.items()}\n",
        "        return decoder_outputs\n",
        "\n",
        "# Example usage\n",
        "# Create an instance of the EncoderDecoderModel with a pre-trained encoder\n",
        "# encoder = Encoder()  # Use your pre-trained encoder here\n",
        "# model = EncoderDecoderModel(encoder, decoders)\n",
        "\n",
        "# # Example input tensor with shape (batch_size, channels, height, width)\n",
        "# input_tensor = torch.randn(2, 1, 512, 512)\n",
        "\n",
        "# # Forward pass\n",
        "# output = model(input_tensor)\n",
        "\n",
        "# # Print the output shapes for each decoder\n",
        "# for param_name, decoder_output in output.items():\n",
        "#     print(f\"{param_name} decoder output shape: {decoder_output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Q3vnXzU5qeEi",
        "outputId": "f601e630-d5f6-40b6-f55c-be5d0012d4d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ba50a98dc4bf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;31m# [RFC-0016](https://github.com/pytorch/rfcs/pull/27) for more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[0;31m# information.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[0;31m# Import removed ops with error message about removal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/masked/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaskedtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_masked_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaskedtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mas_masked_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from ._ops import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0m_canonical_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_generate_docstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/masked/_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mas_masked_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_masked_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorresponding_real_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msym_float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims_common/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m         intersecting_product)\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m from .simplify import (simplify, hypersimp, hypersimilar, logcombine,\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mseparatevars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbesselsimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkroneckersimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignsimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnsimplify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrtdenest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperexpand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/simplify/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0minto\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m from .simplify import (simplify, hypersimp, hypersimilar,\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlogcombine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparatevars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbesselsimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkroneckersimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     signsimp, nsimplify)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/simplify/simplify.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumberfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminpoly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_sum_surds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_minimal_polynomial_sq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombsimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombsimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcse_opts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msub_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperexpand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhyperexpand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formal"
      ],
      "metadata": {
        "id": "ID_yu-w5rj7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "import yaml\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms"
      ],
      "metadata": {
        "id": "n6ByHoxLrIUQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # size: 512x512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 256x256\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # size: 256x256\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 128x128\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # size: 128x128\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # size: 64x64\n",
        "            nn.Flatten(),  # size: 64x64\n",
        "            nn.Linear(64 * 64 * 64, 4096)  # size: 4096\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gsE1KxfDrNYe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MY0InL3QrlfW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self, encoder, decoders):\n",
        "        super(EncoderDecoderModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoders = decoders\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        batch_size = x.size(0)  # Get the batch size\n",
        "        x = x.view(batch_size, -1)  # Flatten the feature tensor, considering the batch size\n",
        "        decoder_outputs = {param_name: decoder(x) for param_name, decoder in self.decoders.items()}\n",
        "        return decoder_outputs"
      ],
      "metadata": {
        "id": "8X957YwXrucK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DAGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_name: str, datasets_folder: str=\"./datasets\", transform=None):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.datasets_folder = datasets_folder\n",
        "        self.dataset_path = os.path.join(self.datasets_folder, self.dataset_name)\n",
        "        self.images_folder = os.path.join(self.dataset_path, \"images\")\n",
        "        self.params_folder = os.path.join(self.dataset_path, \"params\")\n",
        "        self.ranges_file_path = os.path.join(self.dataset_path, \"ranges.yml\")\n",
        "        self.ranges = None\n",
        "        self.transform = transforms.Compose(\n",
        "            [transforms.Resize((512, 512)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        "            ) if transform is None else transform\n",
        "        self.data = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        # Load the ranges from the YAML file\n",
        "        with open(self.ranges_file_path, 'r') as file:\n",
        "            self.ranges = yaml.safe_load(file)\n",
        "        # read images and parameters\n",
        "        data = []\n",
        "        for image_name in os.listdir(self.images_folder):\n",
        "            image_path = os.path.join(self.images_folder, image_name)\n",
        "            param_path = os.path.join(self.params_folder, os.path.splitext(image_name)[0] + \".yml\")\n",
        "            with open(param_path, 'r') as file:\n",
        "                param = yaml.safe_load(file)\n",
        "            # normalize\n",
        "            param = self.preprocess(param)\n",
        "            data.append((image_path, param))\n",
        "        return data\n",
        "\n",
        "    def preprocess(self, param):\n",
        "        processed_param = {}\n",
        "        # for float and vector: normalize with min max\n",
        "        # for states, bool: convert to one hot\n",
        "        # for ints: treat as float, but round back to int when saving as param\n",
        "        for param_name, param_spec in self.ranges.items():\n",
        "            if param_spec['type'] == 'float' or param_spec['type'] == 'int' or param_spec['type'] == 'vector':\n",
        "                processed_param[param_name] = self.normalize(param[param_name], param_spec)\n",
        "            elif param_spec['type'] == 'states' or param_spec['type'] == 'bool':\n",
        "                processed_param[param_name] = self.one_hot(param[param_name], param_spec)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported parameter type: {param_spec['type']}\")\n",
        "        return processed_param\n",
        "\n",
        "    def normalize(self, value, param_spec):\n",
        "        if param_spec['type'] == 'float' or param_spec['type'] == 'int':\n",
        "            return (value - param_spec['min']) / (param_spec['max'] - param_spec['min'])\n",
        "        elif param_spec['type'] == 'vector':\n",
        "            return [(value[i] - param_spec[f'{dim}min']) / (param_spec[f'{dim}max'] - param_spec[f'{dim}min']) for i, dim in enumerate(['x', 'y', 'z'])]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported parameter type: {param_spec['type']}\")\n",
        "\n",
        "    def one_hot(self, value, param_spec):\n",
        "        if param_spec['type'] == 'states':\n",
        "            index = param_spec['values'].index(value)\n",
        "            return [1 if i == index else 0 for i in range(len(param_spec['values']))]\n",
        "        elif param_spec['type'] == 'bool':\n",
        "            # make bools onehot too to make it consistent\n",
        "            return [1, 0] if value else [0, 1]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported parameter type: {param_spec['type']}\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, target = self.data[idx]\n",
        "        sample = Image.open(sample).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        # convert target's values to tensor\n",
        "        for key, value in target.items():\n",
        "            target[key] = torch.tensor(value, dtype=torch.float32)\n",
        "\n",
        "        return sample, target"
      ],
      "metadata": {
        "id": "q2AScdGjzxOp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DAGDataset(\"test_dataset\")"
      ],
      "metadata": {
        "id": "L1bCt3IKz2oT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__getitem__(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JF9dibv02vb",
        "outputId": "4a9df7c9-f651-427b-ed95-4573c6177db0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
              " {'Bm Base Shape': tensor([0., 1.]),\n",
              "  'Bm Size': tensor([0.2754, 0.3033, 0.5714]),\n",
              "  'Floor Ledge Extrusion X': tensor(0.7033),\n",
              "  'Floor Ledge Extrusion Z': tensor(0.8891),\n",
              "  'Floor Ledge Size X': tensor(0.4263),\n",
              "  'Floor Ledge Size Z': tensor(0.1645),\n",
              "  'Has Floor Ledge': tensor([1., 0.]),\n",
              "  'Has Window Ledge': tensor([1., 0.]),\n",
              "  'Num Floors': tensor(0.7500),\n",
              "  'Num Windows Each Side': tensor(0.2500),\n",
              "  'Rf Base Shape': tensor([0., 1., 0.]),\n",
              "  'Rf Size': tensor([0.5063, 0.8231, 0.9543]),\n",
              "  'Window Divided Horizontal': tensor([1., 0.]),\n",
              "  'Window Divided Vertical': tensor([0., 1.]),\n",
              "  'Window Interpanel Offset Percentage Y': tensor(0.8371),\n",
              "  'Window Interpanel Offset Percentage Z': tensor(0.9874),\n",
              "  'Window Ledge Extrusion X': tensor(0.3547),\n",
              "  'Window Ledge Extrusion Z': tensor(0.5499),\n",
              "  'Window Ledge Shape Size': tensor([0.3239, 0.3608, 0.2882]),\n",
              "  'Window Ledges Height Offset': tensor(0.1825),\n",
              "  'Window Panel Area': tensor([0.6837, 0.5403, 0.6459]),\n",
              "  'Window Shape Size': tensor([0.2727, 0.3550, 0.0471]),\n",
              "  'Windows Height Offset': tensor(0.5925),\n",
              "  'Windows Left Right Offset': tensor(0.1235)})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train val and test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "TvkS5mZD388J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ranges from the YAML file\n",
        "with open('./datasets/test_dataset/ranges.yml', 'r') as file:\n",
        "    ranges = yaml.safe_load(file)\n",
        "\n",
        "# Create a mapping between parameter names and output sizes\n",
        "parameter_output_mapping = {}\n",
        "for param_name, param_specs in ranges.items():\n",
        "    if param_specs['type'] == 'float':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'int':\n",
        "        parameter_output_mapping[param_name] = 1  # 1 for scalar\n",
        "    elif param_specs['type'] == 'vector':\n",
        "        parameter_output_mapping[param_name] = 3  # 3 for x, y, z\n",
        "    elif param_specs['type'] == 'states':\n",
        "        parameter_output_mapping[param_name] = len(param_specs['values'])\n",
        "    elif param_specs['type'] == 'bool':\n",
        "        parameter_output_mapping[param_name] = 2  # 2 for binary encoding\n",
        "\n",
        "encoder = Encoder()\n",
        "decoders = nn.ModuleDict({\n",
        "    param_name: Decoder(4096, output_size)\n",
        "    for param_name, output_size in parameter_output_mapping.items()\n",
        "})\n",
        "model = EncoderDecoderModel(encoder, decoders)"
      ],
      "metadata": {
        "id": "6yO4jzvP4AdE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "# for regression, use MSELoss, for classification, use CrossEntropyLoss\n",
        "class EncDecsLoss(nn.Module):\n",
        "    def __init__(self, decoders):\n",
        "        super(EncDecsLoss, self).__init__()\n",
        "        self.decoders = decoders\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0.0\n",
        "        for param_name, decoder_output in outputs.items():\n",
        "            decoder = self.decoders[param_name]\n",
        "            loss += decoder_loss(decoder_output, targets[param_name])\n",
        "        return loss\n",
        "\n",
        "def decoder_loss(decoder_output, target):\n",
        "    # Define your decoder-specific loss function here\n",
        "    # For example, you can use mean squared error (MSE) loss for regression\n",
        "    # or cross-entropy loss for classification\n",
        "    # print(target)\n",
        "    if decoder_output.size(-1) == 1:\n",
        "        return nn.MSELoss()(decoder_output, target)\n",
        "    else:\n",
        "        return nn.CrossEntropyLoss()(decoder_output, target)\n",
        "\n",
        "criterion = EncDecsLoss(decoders)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hZjAuQP34XMR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with train and val\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, targets = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}\")\n",
        "            running_loss = 0.0\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader, 0):\n",
        "            inputs, targets = data\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "        print(f\"Validation loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Save your trained model if needed\n",
        "torch.save(model.state_dict(), \"encDecModel.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC14_rhM4diP",
        "outputId": "7bbef965-fc01-407e-e791-07a4dd85932c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f3d6d4ff1172>:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target[key] = torch.tensor(value, dtype=torch.float32)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pR81YGg6IM1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        inputs, targets = data\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        test_loss += loss.item()\n",
        "    print(f\"Test loss: {test_loss / len(test_loader)}\")\n",
        "print(\"Finished Testing\")"
      ],
      "metadata": {
        "id": "3ebjbXc74dne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}